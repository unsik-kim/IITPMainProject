{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"4\" color=\"black\"><b>Save, compress, and deploy a handwritten digit prediction Keras model</b></font></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr> \n",
    "   <tr style=\"border: none\">\n",
    "       <td style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/raw/master/scikit-learn/hand-written-digits-recognition/images/numbers_banner-04.png\" width=\"600\" alt=\"Icon\"></td>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to train, deploy, and score a Deep Learning model using the Watson Machine Learning service.\n",
    "\n",
    "This notebook specifically shows how to save the trained Deep Learning model as a `.tgz` file locally and deploy the model - the `.tgz` file - online. \n",
    "\n",
    "Some familiarity with Python is helpful. This notebook is compatible with Python 3.6 and uses `keras 2.2.5` and <a href=\"https://dataplatform.cloud.ibm.com/docs/content/analyze-data/environments-parent.html\" target=\"_blank\" rel=\"noopener no referrer\">Watson Studio environments.</a>\n",
    "\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "In this notebook, you will learn how to:\n",
    "\n",
    "- Set up Watson Machine Learning service that can be used to deploy/score online a Deep Learning (Keras) model.\n",
    "- Build a Deep Learning (Keras) model and train it.\n",
    "- Save the trained model - `.tgz` file - in the Watson Machine Learning repository.\n",
    "- Deploy the trained model online and score it.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "1.\t[Set up the environment](#setup)\n",
    "2.\t[Explore data](#data)\n",
    "3.  [Train/evaluate the model](#train)\n",
    "4.\t[Save the model locally](#save)\n",
    "5.\t[Create an online deployment](#deploy)\n",
    "6.\t[Score data](#score)\n",
    "7.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before running the code in this notebook, make sure you meet the following prerequisites:\n",
    "\n",
    "-  A <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance is installed (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>.\n",
    "\n",
    "-  Local python environment configurations:\n",
    "  + Python 3.6\n",
    "  + keras 2.2.5\n",
    "  + watson-machine-learning-client (run code below to install it)\n",
    "  + matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `watson-machine-learning-client` documentation can be found <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">here</a>.  \n",
    "**Tip:** Run the cell below to install `watson-machine-learning-client` package from <a href=\"https://pypi.python.org/pypi\" target=\"_blank\" rel=\"noopener no referrer\">PyPI</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $PIP_BUILD/watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client\n",
      "  Downloading watson_machine_learning_client-1.0.386-py3-none-any.whl (538 kB)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (2.24.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.16.2-py2.py3-none-any.whl (129 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.50.2-py2.py3-none-any.whl (70 kB)\n",
      "Collecting lomond\n",
      "  Downloading lomond-0.3.3-py2.py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (1.25.10)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting ibm-cos-sdk\n",
      "  Downloading ibm-cos-sdk-2.7.0.tar.gz (51 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from requests->watson-machine-learning-client) (2.10)\n",
      "Collecting botocore<1.20.0,>=1.19.2\n",
      "  Downloading botocore-1.19.2-py2.py3-none-any.whl (6.7 MB)\n",
      "Collecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from lomond->watson-machine-learning-client) (1.14.0)\n",
      "Collecting ibm-cos-sdk-core==2.7.0\n",
      "  Downloading ibm-cos-sdk-core-2.7.0.tar.gz (824 kB)\n",
      "Collecting ibm-cos-sdk-s3transfer==2.7.0\n",
      "  Downloading ibm-cos-sdk-s3transfer-2.7.0.tar.gz (133 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (2.8.1)\n",
      "Collecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "Building wheels for collected packages: ibm-cos-sdk, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer\n",
      "  Building wheel for ibm-cos-sdk (setup.py): started\n",
      "  Building wheel for ibm-cos-sdk (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-cos-sdk: filename=ibm_cos_sdk-2.7.0-py2.py3-none-any.whl size=72563 sha256=114612136b7f7be630891ba4e49e0a32b53cb559229b2479e9da1117a69eb4bc\n",
      "  Stored in directory: c:\\users\\seul\\appdata\\local\\pip\\cache\\wheels\\47\\22\\bf\\e1154ff0f5de93cc477acd0ca69abfbb8b799c5b28a66b44c2\n",
      "  Building wheel for ibm-cos-sdk-core (setup.py): started\n",
      "  Building wheel for ibm-cos-sdk-core (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-cos-sdk-core: filename=ibm_cos_sdk_core-2.7.0-py2.py3-none-any.whl size=501004 sha256=2d0f28361fc02854642aadef7df9c026d7579ffe901fe29a33345e20c587c142\n",
      "  Stored in directory: c:\\users\\seul\\appdata\\local\\pip\\cache\\wheels\\6c\\a2\\e4\\c16d02f809a3ea998e17cfd02c13369281f3d232aaf5902c19\n",
      "  Building wheel for ibm-cos-sdk-s3transfer (setup.py): started\n",
      "  Building wheel for ibm-cos-sdk-s3transfer (setup.py): finished with status 'done'\n",
      "  Created wheel for ibm-cos-sdk-s3transfer: filename=ibm_cos_sdk_s3transfer-2.7.0-py2.py3-none-any.whl size=88607 sha256=14c988517973cac5fabcc85ea649b0385b0f3eb045ed6f0298c5ddf427bc8942\n",
      "  Stored in directory: c:\\users\\seul\\appdata\\local\\pip\\cache\\wheels\\5f\\b7\\14\\fbe02bc1ef1af890650c7e51743d1c83890852e598d164b9da\n",
      "Successfully built ibm-cos-sdk ibm-cos-sdk-core ibm-cos-sdk-s3transfer\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3, tqdm, lomond, tabulate, docutils, ibm-cos-sdk-core, ibm-cos-sdk-s3transfer, ibm-cos-sdk, watson-machine-learning-client\n",
      "Successfully installed boto3-1.16.2 botocore-1.19.2 docutils-0.15.2 ibm-cos-sdk-2.7.0 ibm-cos-sdk-core-2.7.0 ibm-cos-sdk-s3transfer-2.7.0 jmespath-0.10.0 lomond-0.3.3 s3transfer-0.3.3 tabulate-0.8.7 tqdm-4.50.2 watson-machine-learning-client-1.0.386\n",
      "Collecting watson-machine-learning-client\n",
      "  Using cached watson_machine_learning_client-1.0.386-py3-none-any.whl (538 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: lomond in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: tabulate in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: certifi in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (2.24.0)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (4.50.2)\n",
      "Requirement already satisfied, skipping upgrade: urllib3 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (1.25.10)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from watson-machine-learning-client) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.15.4 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (1.18.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from pandas->watson-machine-learning-client) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from lomond->watson-machine-learning-client) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-core==2.7.0 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: ibm-cos-sdk-s3transfer==2.7.0 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from requests->watson-machine-learning-client) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.20.0,>=1.19.2 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from boto3->watson-machine-learning-client) (1.19.2)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from boto3->watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\envs\\clone\\lib\\site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\n",
      "Installing collected packages: watson-machine-learning-client\n",
      "Successfully installed watson-machine-learning-client-1.0.386\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Authenticate the Watson Machine Learning service on the IBM Cloud.**\n",
    "\n",
    "**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-get-wml-credentials.html\" target=\"_blank\" rel=\"noopener no referrer\">Service credentials</a> tab of the service instance that you created on the IBM Cloud. <BR>If you cannot find the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n",
    "\n",
    "**Action**: Enter your WML service instance credentials in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    'apikey': 'yKzKXryIx36LG27up7ht3n5fTDTdy2KI3EPsbwj575p3',\n",
    "    'url': 'https://us-south.ml.cloud.ibm.com',\n",
    "    'instance_id': '2eff0a95-2c9c-4912-b289-789a09b3ffc4'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import `watson-machine-learning-client` and authenticate the service instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'joblib' from 'sklearn.externals' (C:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\sklearn\\externals\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-987067e9d939>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWatsonMachineLearningAPIClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWatsonMachineLearningAPIClient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_python_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\client.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_system\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLearningSystem\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExperiments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepository\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRepository\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefinitions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefinitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\repository.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwml_client_error\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwml_resource\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWMLResource\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefinitions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDefinitions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiments\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mExperiments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\models.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlrepositoryartifact\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLRepositoryArtifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlrepository\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMetaProps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMetaNames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\libs\\repo\\mlrepositoryartifact\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mml_repository_artifact\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLRepositoryArtifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspark_artifact_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkArtifactLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspark_pipeline_artifact\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkPipelineArtifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\libs\\repo\\mlrepositoryartifact\\ml_repository_artifact.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlib_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstalled_libs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSCIKIT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlrepositoryartifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_pipeline_model_artifact\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mScikitPipelineModelArtifact\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\libs\\repo\\mlrepositoryartifact\\scikit_pipeline_model_artifact.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlib_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstalled_libs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSCIKIT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlrepositoryartifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscikit_pipeline_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mScikitPipelineReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mwatson_machine_learning_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmlrepositoryartifact\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxgboost_model_reader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBoostModelReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseEstimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\watson_machine_learning_client\\libs\\repo\\mlrepositoryartifact\\scikit_pipeline_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlib_checker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstalled_libs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSCIKIT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ScikitPipelineReader'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'joblib' from 'sklearn.externals' (C:\\ProgramData\\Anaconda3\\envs\\clone\\lib\\site-packages\\sklearn\\externals\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WatsonMachineLearningAPIClient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-a33e32c8245a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWatsonMachineLearningAPIClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwml_credentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'WatsonMachineLearningAPIClient' is not defined"
     ]
    }
   ],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore data <a id=\"data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will check what the input data looks like.\n",
    "You need `keras.datasets.mnist` and `matplotlib.pyplot` modules to see what each digit looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the MNIST data set from the `keras.datasets.mnist` module and split the data set into training and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade keras==2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `matlplotlib.pyplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Paramters of \"display_digits\" function:\n",
    "\n",
    "plt     - matplotlib's pyplot module.\n",
    "images  - The array of images. Ex) X_train, X_test in our example\n",
    "labels  - Labels of mapping images. \n",
    "start   - Start index of \"images\" array.\n",
    "end     - End index of \"images\" array.\n",
    "num_row - Number of rows.\n",
    "title   - Title of every image that will be displayed. Ex) Training or Test\n",
    "'''\n",
    "def display_digits(plt, images, labels, start, end, num_row, title):\n",
    "    images_and_labels = list(zip(images, labels))\n",
    "    num_col = int(end/num_row) if (end % 2 == 0) else int(end/num_row) + 1\n",
    "\n",
    "    for index, (image, label) in enumerate(images_and_labels[start:end]):\n",
    "        plt.subplot(num_row, num_col, index + 1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title(title + ': %i' % label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_digits(plt, X_train, y_train, 0, 5, 2, 'Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test data sets shape and correponding label arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save copies of `X_test` and `y_test` for scoring in section [6. Score](#score) before reshaping them in section [3.1 Train the model](#train_sub)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_score = X_test.copy()\n",
    "y_test_score = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train and evaluate the model <a id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will build a Deep Learning (Keras) model, train it, and evaluate it.\n",
    "\n",
    "Import the required package and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train the model <a id=\"train_sub\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters that are required for the Deep Learning (Keras) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen in section [2. Explore data](#data), the image size is 28x28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the digits to be in the range of [0-1] instead of [0-255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the label arrays of training/test digit images into one hot format matrix.\n",
    "\n",
    "Ex)  \n",
    "0 => [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
    "1 => [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
    "2 => [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]  \n",
    ".  \n",
    ".  \n",
    ".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Conv2D layer\n",
    "    - The first 2D convolution layer has 32 output filters and the second 2D convolution layer has 64 output filters.\n",
    "    - `kernel_size` specifies the height and width of the 2D convolution window.\n",
    "    - `activation` is a non-linear function that applies to the output of the layer. `relu` (rectified linear unit) clamps all values below 0 to 0.\n",
    "- MaxPooling layer\n",
    "    - Max pooling basically moves a `m`x`n` window across a 2D input space where `m` and `n` are both 2 in this example. The max value within the window is the output.\n",
    "- Dropout layer\n",
    "    - Helps the model to avoid overfitting.\n",
    "- Dense layer\n",
    "    - A regular densely-connected Neural Network layer.\n",
    "- Flatten layer\n",
    "    - Flattens the input and doesn't affect the batch size.\n",
    "- Adadelta \n",
    "    - Adapts learning rates based on a moving window of gradient updates instead of accumulating all past gradients. This way, Adadelta continues learning even when many updates occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model with the parameters you set before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "          y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model accuracy on the train and validation (test) data sets. You will plot the graphs in `R`'s `ggplot` style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the model loss on the train and validation (test) data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train loss', 'test loss'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy: {:.2f}%'.format(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save the model locally <a id=\"save\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will learn how to save the train Deep Learning (Keras) model locally and compress it into a `.tgz` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, save the Keras model locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import suppress\n",
    "import os\n",
    "\n",
    "filename = 'keras_mnist_model.h5'\n",
    "\n",
    "# Delete a duplicate file if exists.\n",
    "with suppress(OSError):\n",
    "    os.remove(filename)\n",
    "    \n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the Keras model file into a `.tgz` file. Make sure to add the `z` flag when running the `tar` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compress keras model\n",
    "tar_filename = filename + '.tgz'\n",
    "cmdstring = 'tar -zcvf ' + tar_filename + ' ' + filename\n",
    "os.system(cmdstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the model file (keras_mnist_model.h5) and its compressed version (keras_mnist_model.h5.tgz) are both saved in the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create an online deployment <a id=\"deploy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you learn how to deploy the compressed version - the `.tgz` file - of the trained model described in section [4. Save the model locally](#save) online.\n",
    "\n",
    "First, let's instantiate a `WatsonMachineLearningAPIClient` object with your WML credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define metadata for the trained model in section [3. Train and evaluate the model](#train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    client.repository.ModelMetaNames.NAME: 'MNIST - compressed keras model',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: 'tensorflow',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: '1.15',\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION: '3.6',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [{'name':'keras', 'version': '2.2.5'}]\n",
    "}\n",
    "\n",
    "published_model_details = client.repository.store_model(model=tar_filename, meta_props=model_props)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the `uid` for the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uid = client.repository.get_model_uid(published_model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can deploy the stored model as a web service (online) by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = client.deployments.create(model_uid, 'Keras MNIST model deployment through compressed file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list the deployed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score data <a id=\"score\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will learn how to score a test data record.\n",
    "\n",
    "First, extract the scoring endpoint from the deployment details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first digit of `X_test` will be used for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_data = X_test[0].tolist()\n",
    "display_digits(plt, X_test_score, y_test_score, 0, 1, 1, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map keys - 'fields' and 'values' - to their corresponding values in the `scoring payload` dictionary and score the model. However, only 'values' will be used in this example - map 'values' to `scoring_data` in the `scoring payload` dictionary ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload = {'values': [scoring_data]}\n",
    "scores = client.deployments.score(scoring_endpoint, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the following cell, the predicted label (`prediction_classes`) in the result of the above cell) and the true label are the same - `7`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and next steps <a id=\"summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook! \n",
    " \n",
    "You learned how to train, evaluate, and score a Keras model. You also learned how to deploy the model in a `.tgz` format via `watson-machine-learning-client` package.\n",
    " \n",
    "Check out our <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Jihyoung Kim**, Ph.D., is a Data Scientist at IBM who strives to make data science easy for everyone through Watson Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019, 2020 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
