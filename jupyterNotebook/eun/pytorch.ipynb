{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.1 텐서를 만드는 법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. torch.Tensor 함수로 Numpy와 리스트 객체로부터 텐서를 생성할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# list로부터 2x3 텐서 생성\n",
    "x_list = [[1,2,3],[4,5,6]]\n",
    "x = torch.Tensor(x_list)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "#numpy array로부터 2x3텐서 생성\n",
    "x_numpy = np.array([[1,2,3],[4,5,6]])\n",
    "print(x_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9., 6., 1.],\n",
      "        [5., 3., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(np.array([[9,6,1],[5,3,2]]))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .tolist() 혹은 .numpy()명령어를 통해 다시 원래의 자료구조로 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[[9.0, 6.0, 1.0], [5.0, 3.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "#.tolist()\n",
    "x_back2list = x.tolist()\n",
    "print(type(x_back2list))\n",
    "print(x_back2list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.0, 6.0, 1.0], [5.0, 3.0, 2.0]]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#.numpy()\n",
    "x_back2numpy = x.tolist()\n",
    "print(x_back2numpy)\n",
    "print(type(x_back2numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본적으로 텐서 생성 시 CPU 상태 디바이스 정보를 가지고 있으며,\n",
    "#### '.device'속성을 조회하면 현재 사용하고 있는 디바이스 정보를 알 수 있다.\n",
    "* GPU 텐서를 만드는 방법은 텐서에서 '.to'함수를 호출 시 'cuda'라는 문자열 인자를 전달하거나 '.cuda()'함수를 호출한다.\n",
    "* 만약에 CPU를 다시 사용하고 싶다면 다시 'cpu'문자열을 .to()함수에 전달하거나 '.cpu()'함수를 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#기본 device정보\n",
    "print(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e19909287cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#GPU사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "#GPU사용\n",
    "x = x.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(torch.rand(2,3))\n",
    "print(torch.randint(low=0, high=8, size=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
